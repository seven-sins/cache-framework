# 服务端口
server.port = 9999

# mapper
# 此处配置使用注解@Value获取失败, 暂用在启动类上使用@MapperScan扫描
mybatis.params.mapperLocation=com.lonecpp.redis.mapper

# dataSource
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://192.168.0.208:3306/cache_framework?characterEncoding=utf8
spring.datasource.username=root
spring.datasource.password=login
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

# redis cluster
spring.redis.cache.clusterNodes=192.168.0.205:7001,192.168.0.205:7002,192.168.0.206:7003,192.168.0.206:7004,192.168.0.207:7005,192.168.0.207:7008

# kafka配置
#spring.kafka.topic=cache-topic
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=192.168.0.205:9092,192.168.0.206:9092,192.168.0.207:9092
# 指定默认消费者group id
#spring.kafka.consumer.group-id=cache-group
# 指定默认topic id
#spring.kafka.template.default-topic=default-topic
# 指定listener 容器中的线程数，用于提高并发量
#spring.kafka.listener.concurrency=3
# 每次批量发送消息的数量
#spring.kafka.producer.batch-size=1000
# 消息编码解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer


kafka.broker.address=192.168.0.205:9092,192.168.0.206:9092,192.168.0.207:9092
kafka.zookeeper.connect=192.168.0.205:2181,192.168.0.206:2181,192.168.0.207:2181
kafka.topic=cache-topic